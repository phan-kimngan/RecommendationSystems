{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Recommendation System.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNAB95cxBoAO0ptsVSbt9LV"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"4SU0yazd0HRA","colab_type":"text"},"source":["# **XÂY DỰNG HỆ THỐNG GỢI Ý SẢN PHẨM**\n","# ***Recommendation Systems***"]},{"cell_type":"markdown","metadata":{"id":"iHvU0UrR3EKS","colab_type":"text"},"source":["## **1. Giới thiệu**\n","\n","Nhằm phục vụ cho việc kinh doanh của các doanh nghiệp trở nên tốt hơn hay tối đa chi phí và thời gian đầu tư, hệ thống gợi ý (Recommendation System) ra đời nhằm dự đoán sở thích của người dùng và tìm kiếm các đối tượng tiềm năng phù hợp với sở thích đó để gợi ý cho người dùng. Hệ thống Recommendation được xem như là một robot với công việc \"se duyên\" sản phẩm của công ty với người dùng. Nó có khả năng tự tìm kiếm và gợi ý những sản phẩm của công ty mà có thể người dùng rất thích nhưng chưa từng biết đến. \n","\n","Ví dụ một hệ thống Recommendation rất quen thuộc mà chúng ta trải nghiệm mỗi ngày, chẳng hạn khi chúng ta tìm kiếm trên youtube để xem một chương trình ca nhạc và sau đó, liên tục những chương trình ca nhạc tập tiếp theo được youtube tự động gợi ý, ít khi youtube gợi ý một bộ phim hay một bản nhạc có đề tài chẳng liên quan. Hệ thống Recommendation của Youtube rất \"thông minh\" và \"tinh tế\" khi tự động tìm kiếm và gợi ý điều chúng ta có thể thích dù chưa hề nghĩ đến hay tương tác với chúng. Hiện tại, bản Youtube \"xịn xò\" hơn khi ghi dòng chữ *Recommended for you* dưới những bản được xuất hiện sau đó.\n","\n","Các thành phần cơ bản của hệ thống Recommendation bao gồm: users là các người dùng tương tác với công ty, items là các sản phẩm của công ty, và ratings là các phản hồi, đánh giá của người dùng với sản phẩm. \n","\n","Bài toán recommendation system có 2 dạng chính:\n","\n","- Content-based systems: gợi ý items theo các items mà users sử dụng trong quá khứ, dựa vào đặc tính của items đã được phân từng nhóm, dựa vào đó xây dựng mô hình dự đoán tối ưu.\n","\n","- Collaborative filtering: gợi ý items dựa trên sự tương quan giữa các users và/hoặc items. Phần này có 2 dạng: Neighborhood-based Collaborative Filtering và Matrix Factorization Collaborative Filtering. Neighborhood-based Collaborative Filtering dựa vào sự tương quan của users hay items để đưa ra gợi ý bằng công thức. Matrix Factorization Collaborative Filtering cho rằng tồn tại nhân tố ẩn tương quan giữa users và items, từ đó xây dựng mô hình dự đoán tối ưu.\n","\n","## **2. Hệ thống Content-based Filtering**\n","\n","Hệ thống **Content-based Filtering** sử dụng các tính năng của các items để đề xuất các items khác tương tự như những gì users thích, dựa trên các hành động trước đó của họ hoặc phản hồi của họ. Trong bài viết [Content-based Recommendation Systems](https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/) của trang Machine Learning Cơ Bản đã đề cập chi tiết về phần này. Trước tiên cần xây dựng ma trận của các đặc trưng của items dựa vào hành vi tương tác của users với items trong quá khứ rồi dùng chúng đưa ra dự đoán. Ví dụ, user A đã đọc rất nhiều các quyển sách như \"Đắc Nhân Tâm\", \"Cà phê cùng Tony\" hệ thống sẽ gợi ý nhiều quyển sách cùng thể loại kĩ năng sống cho user A, ví dụ như \"Sức mạnh tiềm thức\". Nhưng user B lại khác, anh ấy hay xem nhiều sách lịch sử như \"Vua Gia Long\", \"Đại Việt Sử Ký Toàn Thư\", hệ thống lúc này sẽ tinh ý gợi ý quyển sách \"Các triều đại Việt Nam\" cho user B.\n","\n","**2.1.   Vector đặc trưng của item**\n","\n","Các đặc trưng items của các quyển sách trên cần xây dựng ở đây là nhóm sách kĩ năng, nhóm sách lịch sử. Trong toán học 2 đặc trưng này được xây dựng bởi vector 2 chiều: chiều 1 là nhóm sách kĩ năng, chiều thứ 2 là nhóm sách lịch sử. Tương tự như thế, hệ thống sẽ xây dựng được vecto $\\mathbf{x}_m$ cho items thứ m có số chiều dựa trên các đặc trưng yêu thích của $N$ users.\n","Một số phương pháp thường được sử dụng để xây dựng vector đặc trưng của items là:\n","\n","Phương pháp đề suất là sử dụng TF-IDF (Term frequency-Inverse Document Frequency)\n","\n","Việc tiếp theo, hệ thống đưa ra dự đoán yêu thích của user thứ n đến item thứ m . Chẳng hạn như hệ thống đã dự đoán được user B có khả năng sẽ thích quyển sách \"Các triều đại Việt Nam\" nên đã đưa ra đề xuất.\n","\n","**2.2.   Mô hình dự đoán \"yêu thích\" của các users** \n","\n","Xây dựng mô hình cho mỗi users có thể được coi như bài toán Regression hoặc Classsification với dữ liệu đầu vào là đặc trưng các items và các đánh giá user đó đã sử dụng. Việc xây dựng mô hình dự đoán cho mỗi user không phụ thuộc vào các users khác mà phụ thuộc vào các đặc trưng của mỗi items. Ứng với mỗi user thứ $n$, cần tìm một mô hình dự đoán \"yêu thích\" cho user đó là tốt nhất. Ở đây, chúng ta áp dụng mô hình *hồi quy tuyến tính*. \n","\n","$\\mathbf{Y}\\approx\n","\\left[ \\begin{matrix}\n","{x}_{11} & {x}_{21} & \\dots & {x}_{L1}\\\\\n","{x}_{12} & {x}_{22} & \\dots & {x}_{L2}\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","{x}_{1M} & {x}_{2M} & \\dots & {x}_{LM}\\\\\n","\\end{matrix} \\right]\n","\\left[ \\begin{matrix}\n","{w}_{11} & {w}_{12} & \\dots & {w}_{1N}\\\\\n","{w}_{21} & {w}_{22} & \\dots & {w}_{2N}\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","{w}_{L1} & {w}_{L2} & \\dots & {w}_{LN}\\\\\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}^T_1\\mathbf{w}_1 & \\mathbf{x}^T_1\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_1 \\mathbf{w}_N\\\\\n","\\mathbf{x}^T_2\\mathbf{w}_1 & \\mathbf{x}^T_2\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_2 \\mathbf{w}_N\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","\\mathbf{x}^T_M\\mathbf{w}_1 & \\mathbf{x}^T_M\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_M \\mathbf{w}_N\\\\\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}^T_1 \\\\\n","\\mathbf{x}^T_2 \\\\\n","\\dots \\\\\n","\\mathbf{x}^T_M \\\\\n","\\end{matrix} \\right]\n","\\left[ \\begin{matrix}\n","\\mathbf{w}_1 & \\mathbf{w}_2 & \\dots & \\mathbf{w}_N\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}_1 & \\mathbf{x}_2 & \\dots & \\mathbf{x}_M\n","\\end{matrix} \\right]^T\\left[ \\begin{matrix}\n","\\mathbf{w}_1 & \\mathbf{w}_2 & \\dots & \\mathbf{w}_N\n","\\end{matrix} \\right]=\n","\\mathbf{X}^{T}\\mathbf{W}$\n","\n","Với:\n","* $N$ là số lượng users\n","* $M$ là số lượng items\n","* $L$ là số lượng đặc trưng items\n","* $\\mathbf{Y}$ là ma trận user-item thể hiện sự quan tâm của từng user đối với từng item, còn gọi là ma trận Utility. Ma trận $Y$ có nhiều ô bị khuyết dữ liệu vì không phải user nào cũng chịu khó đánh giá và phản hồi ý kiến cho item. \n","*  $\\mathbf{X} \\in \\mathbb{R}^{L \\times M}$  là ma trận của toàn bộ các đặc trưng items bao gồm các vecto đặc trưng của items với mỗi cột tương ứng là 1 vecto đặc trưng item.\n","* $\\mathbf{W} \\in \\mathbb{R}^{L \\times N}$ là ma trận của toàn bộ các mô hình của users với mỗi cột tương ứng với một user.\n","* $\\mathbf{R} \\in \\mathbb{R}^{M \\times N}$ là ma trận thể hiện việc một user đã đánh giá một item hay chưa. $r_{mn}=1$ nếu user thứ n đã đánh giá sản phẩm thứ m, $r_{mn}=0$ nếu user thứ n chưa đánh giá sản phẩm thứ m\n","\n","**Mô hình hồi quy tuyến tính**\n","\n","Các giá trị bị khuyết $\\mathbf{y}_{mn}$ tại hàng m cột n của $\\mathbf{Y}$ dự đoán được sự quan tâm của user thứ n đối với sản phẩm m được mô tả dưới mô hình hồi quy tuyến tính như sau:\n","\n","$y_{mn}=\\mathbf{x}_m^{T}\\mathbf{w}_n+b_{n}$, $m=\\overline{1..M}, n=\\overline{1..N}$\n","\n","Trong đó, giá trị $y_{mn}$  là mức độ quan tâm của user thứ n với item thứ m, $\\mathbf{x}_m$ là vecto đặc trưng của item thứ m, $b_{n}$ là bias. Quá trình học mô hình, sẽ tìm ra hệ số $\\mathbf{w}_m$ và $b_{n}$\n","\n","Xét một user thứ $n$ bất kỳ, hàm mất mát regularized có thành phần regularization được xây dựng như hồi quy Ridge Regression.\n","\n","$\\mathbb{L}(\\mathbf{w}_n) = \\frac{1}{2} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m^{T}\\mathbf{w}_n +b_{n}- y_{mn})^2 + \\frac{\\lambda}{2}||\\mathbf{w}_n||_2^2$\n","\n","Mục tiêu của học máy là tối thiểu hàm mất mát nhưng vẫn đảm bảo chất lượng dự đoán của mô hình. Việc tối thiểu hàm mất mát regularized trên, nói một cách tương đối, là việc tối thiểu cả hàm mất mát của Linear Regression và số hạng regularization. Với số hạng đầu tiên ở vế phải chính là hàm mất mát của Linear Regression, là phần sai lệch giữa kết quả của mô hình dự đoán và thực tế, trong đó $r_{mn} = 1$ nếu item thứ m đã được đánh giá bởi user thứ n. Số hạng thứ hai có ${\\lambda}$ là hệ số dương và phần regularization, giúp các mô hình phức tạp giảm overfiting. Số hạng có công dụng làm di chuyển nghiệm của bài toán tối ưu hàm mất mát theo hướng làm cho mô hình ít phức tạp hơn mặc dù giá trị của hàm mất mát có tăng lên một ít, hay nói cách khác là làm giảm bậc của đa thức mà không phải thay đổi số lượng feature. Sở dĩ regularization được chọn là $||\\mathbf{w}_n||_2^2$ là vì đạo hàm của nó là $\\mathbf{w}$, liên tục tại mọi điểm, việc tối thiểu regularization $||\\mathbf{w}_n||_2^2$ đồng nghĩa với việc khiến cho các giá trị của nó tiến gần về 0.\n","\n","Trung bình lỗi trong số các items mà user thứ n đã rated được tính như sau:\n","\n","$\\mathbb{L}(\\mathbf{w}_n) = \\frac{1}{2s_n} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x_m}^{T}\\mathbf{w_n} + b_{n} - y_{mn})^2 + \\frac{\\lambda}{2}||\\mathbf{w}_n||_2^2 $\n","\n","Với $s_n=\\sum_{m=1}^M r_{mn}$ là số lượng các items mà user thứ n đã đánh giá\n","\n","Vì biểu thức hàm mất mát chỉ phụ thuộc vào các items đã được đánh giá, nên rút gọn bằng cách, $\\hat{\\mathbf{y}}$ là vecto bao gồm các thành phần đã đánh giá của cột thứ n của ma trân $\\mathbf{Y}$ tương tự $\\hat{\\mathbf{X}}$ là vecto được trích từ các cột tương ứng với các items đã được rated bởi user thứ $n$ của $\\mathbf{X}$. Hàm mất mát regularized được viết lại như sau:\n","\n","$\\mathbb{L}(\\mathbf{w}_n) = \\frac{1}{2s_n} ||\\hat{\\mathbf{X}}^T_n\\mathbf{w}_n + b_n\\mathbf{e_n}- \\hat{\\mathbf{y}}||^2 + \\frac{\\lambda}{2}||\\mathbf{w}_n||_2^2$\n","\n","Với  $\\mathbf{e_n}$ là vector cột chứa $s_n$ phần tử 1. Giá trị $\\mathbf{w}_n$ có thể được tìm qua Stochastic Gradient Descent (SGD), hoặc Mini-batch GD để $\\mathbb{L}_n$ đạt giá trị nhỏ nhất.\n","\n","**Stochastic gradient descent (SGD)**\n","\n","Đạo hàm của $\\mathbb{L}_n$ :\n","\n","$\\nabla_{\\mathbf{w}_{n}}\\mathbb{L}=\\frac{\\partial \\mathbb{L}(\\mathbf{w}_n)}{\\partial \\mathbf{w}_n} = \\frac{1}{s_n}\\hat{\\mathbf{X}}_n(\\hat{\\mathbf{X}}^T_n\\mathbf{w}_n+b_n\\mathbf{e_n}-\\hat{\\mathbf{y}}_n) + \\lambda\\mathbf{w}_n$\n","\n","Sơ lược một chút về giải thuật SGD để tìm nghiệm cho phương trình đạo hàm trên. Phương thức hoạt động SGD tương tự như Gradient Descent (GD) nhưng khác ở chỗ, để khắc phục nhược điểm dữ liệu khá lớn và tốn nhiều thời gian để học của GD, mỗi vòng lặp của SGD, ta tính đạo hàm của hàm mất mát chỉ dựa trên một điểm dữ liệu $\\mathbf{x}_i$ thay vì $\\mathbf{X}$  rồi cập nhật $\\mathbf{w}_n$ dựa trên đạo hàm này. Ở bài toán trên, ta cần tìm $\\mathbf{w}_{n_*}$ sao cho $\\mathbb{L}$ đạt giá trị nhỏ nhất tại đó. Giả sử ta có đạo hàm số tại $\\mathbf{w}_{n_t}$ là $f'(\\mathbf{w}_{n_t})$: $f'(\\mathbf{w}_{n_t})>0$ khi $\\mathbf{w}_{n_t}$ nằm bên phải $\\mathbf{w}_{n_*}$ và ngược lại, để điểm \n","$\\mathbf{w}_{n_{t+1}}$ gần với $\\mathbf{w}_{n_*}$ cần di chuyển về phía bên trái, tức về phía âm. Nói cách khác, ta cần di chuyển ngược dấu với đạo hàm, từ đó có thể đưa ra nhận xét rằng nếu ta cố gắng đi ngược hướng đạo hàm thì nhanh chóng đến được điểm cực tiểu của hàm số. Giải thuật GD sẽ cập nhật tham số $\\mathbf{w}_{n_t}$ đi ngược hướng với gradient $\\nabla_{\\mathbf{w}_n}\\mathbb{L}(\\mathbf{w}_{n_t})$ ở điểm $\\mathbf{w}_{n_t}$, nghĩa là $\\mathbf{w}_{n_t}$ sẽ được xê dịch 1 đoạn $-\\eta\\nabla_{\\mathbf{w}_{n}}\\mathbb{L}(\\mathbf{w}_{n_t})$ với $\\eta>0$ là tốc độ học. \n","\n","$\\mathbf{w}_{n_t}=\\mathbf{w}_{n_t}-\\eta\\nabla_{\\mathbf{w}_{n}}\\mathbb{L}(\\mathbf{w}_{n_t})$\n","\n","Tiếp tục quy trình như thế sau mỗi lần cập nhật cho tới khi nó hội tụ về điểm nhỏ nhất $\\mathbf{w}_{n_*}$."]},{"cell_type":"markdown","metadata":{"id":"rg9dMuOlgNoj","colab_type":"text"},"source":["## **3. Hệ thống Neighborhood-based Collaborative Filtering**\n","\n","Hệ thống **Neighborhood-based Collaborative Filtering (NBCF)** khác với **Content-based Filtering**. Hệ thống **Content-based Filtering** cần phải xây dựng hệ thống mô tả cho mỗi item,  bản mô tả này có thể được xây dựng bởi nhà cung cấp hoặc được thu thập bằng cách yêu cầu users đánh giá cho items, mà thực tế, ít users nào chịu khó bỏ thời gian và công sức đánh giá cho các items, sự yêu cầu này nhiều khi còn gây phiền toái cho các users. \n","\n","Để khắc phục điều này, hệ thống **NBCF** được xây dựng dựa trên *sự tương đồng gần nhất* của các users để dự đoán sự yêu thích items của users. Trường hợp này gọi là ***User-user collaborative filtering***. Hệ thống dựa vào hành vi tương tác items của các users, các hành vi này thường được phân nhóm thành một vài nhóm đơn giản, nếu biết hành vi mua hàng của một vài users trong nhóm, hệ thống sẽ suy luận ra hành vi của những users còn lại. Ví dụ, user A và B đều đã đọc quyển \"Nhà giả kim\" và đều đánh giá là 5 sao, nhưng user A vừa mới xem và đánh giá 5 sao cho quyển sách \"Rừng Na Uy\", điều này có khả năng user B cũng thích quyển sách này, hệ thống nhanh chóng gợi ý quyển này cho user B. \n","\n","Một hướng tiếp cận khác được cho là làm việc hiệu quả hơn là ***Item-item collaborative filtering***. Thay vì xác định sự tương đồng của các users, hệ thống sẽ xác định sự tương đồng của các items và đưa gợi ý những items gần giống với những items mà user có mức độ quan tâm cao. Ví dụ, user A đã đánh giá quyển \"Hiệu ứng chim mồi - Tập 1\" là 5 sao, mà quyển \"Hiệu ứng chim mồi - Tập 1\" khá \"tương đồng\" và liên quan với quyển \"Hiệu ứng chim mồi - Tập 2\", có thể user A sẽ thích, hệ thống sẽ tinh ý gợi ý quyển này cho user A. Có thể xem chi tiết tại mã nguồn tham khảo [Neighborhood-Based Collaborative Filtering](https://machinelearningcoban.com/2017/05/24/collaborativefiltering/).\n","\n","### **3.1. User-user collaborative filtering**\n","\n","**3.1.1. Hàm tương đồng của các users**\n","![alt text](https://viblo.asia/uploads/952f2e90-dc82-4879-ba3e-ebc03af6bb87.png)\n","\n","Điều này xuất phát từ ma trận Utility $\\mathbf{Y}$ để quyết định sự tương quan của các users\n","\n","Trong hệ thống recommendation, mỗi user sẽ có mức độ quan tâm tới từng item khác nhau được thể hiện dưới mặt toán học là ma trận Utility. Các ô của ma trân Utility được gán một giá trị tương ứng với mỗi cặp user-item nếu giá trị này đã biết, nghĩa là user đó đã đánh giá item đó, và được gán $?$ nếu giá trị này chưa biết, nghĩa là user đó chưa đánh giá về item đó, mục tiêu là đi dự đoán giá trị gần với giá trị thật của chúng.\n","Hàng cuối cùng trong hình a) là giá trị trung bình cộng của các đánh giá cho mỗi user. Chuẩn hóa ma trận Utility trong hình (b) bằng cách trừ các giá trị đánh giá cho trung bình cộng của mỗi user, dấu ? tạm thay thế là 0. \n","\n","Cosine Similarity là một thước đo độ tương tự để tính độ giống nhau hay còn gọi là độ tương đồng giữa users trong mô hình không gian các users. Cột của ma trận chuẩn hóa Utility là vecto đánh giá của N users tới M items có dạng $\\mathbf{y_i}=(y_{1i}, y_{2i},..., y_{Mi})^T$, $\\mathbf{y_j}=(y_{1j}, y_{2j},..., y_{Mj})^T$ với $i,j=\\overline{1..N}$. Độ tương đồng được tính theo công thức:\n","\n","$\\text{cosin}(\\mathbf{y_i}, \\mathbf{y_j})=\\frac{\\mathbf{y}_i^T\\mathbf{y}_j}{||\\mathbf{y}_i||_2||\\mathbf{y}_j||_2}= \\frac{\\sum_{k = 1}^My_{ki}*y_{kj}}{\\sqrt{\\sum_{k= 1}^My_{ki}^2}\\sqrt{\\sum_{l= 1}^My_{kj}^2}}$\n","\n","Hàm số $cosin$ đo góc của 2 vecto users đánh giá, giá trị hàm số trong đoạn $[-1, 1]$. Hàm số cos của một góc bằng 1 nghĩa là góc giữa hai vector bằng $0^0$, thể hiện hai vector users hoàn toàn tương đồng nhau. Hàm số cos của một góc bằng -1 nghĩa là góc giữa hai vector bằng $180^0$, thể hiện hai vector này hoàn toàn trái ngược nhau.\n","\n","**3.1.2. Dự đoán \"yêu thích\" của các users**\n","\n","Bài toán đặt ra là dự đoán các giá trị thật sự của $?$ trong ma trận Utility $\\mathbf{Y}$, nghĩa là dự đoán các giá trị đánh giá của các user thứ n chưa đánh giá item thứ m. Quy trình là xác định các users khác đã đánh giá item thứ m đó, chọn ra 1 số users trong đó có sự tương đồng cao của các user thứ n, trích xuất giá trị đánh giá của các users đó trên item m và thực hiện công thức: \n","\n","$\\hat{y}_{mn}= \\frac{\\sum_{\\mathbf{y_j} \\in \\mathcal{N}(u_n, i_m)} \\bar{y}_{mj} \\text{cosin}(\\mathbf{y_n}, \\mathbf{y_j})}{\\sum_{\\mathbf{y_j} \\in \\mathcal{N}(u_n, i_m)} |\\text{cosin}(\\mathbf{y_n}, \\mathbf{y_j})|}$\n","\n","Trong đó:\n","\n","* $\\mathbf{y_j}$: là vecto đánh giá của user thứ j.\n","\n","* $\\mathcal{N}(u_n, i_m)$: là tập hợp users đã đánh giá item m và có độ tương đồng với users n đó cao nhất.\n","\n","* $\\text{cosin}(\\mathbf{y_n}, \\mathbf{y_j})$: là độ tương đồng cosin giữa đánh giá của user thứ n và đánh giá của user thứ j.\n","\n","* $\\bar{y}_{mj}$: là giá trị đánh giá của các users trong $\\mathcal{N}(\\mathbf{u_n}, \\mathbf{i_m})$ với item thứ m.\n","\n","Hình c là kết quả của quá trình dự đoán theo công thức này.\n","\n","### **3.2. Item-Item collaborative filtering**\n","\n","Thay vì tính toán độ tương đồng của các user, hệ thống sẽ tính sự tương đồng của các user. Cách tiếp cận thứ hai này được gọi là **Item-item Collaborative Filtering**. Cách dự đoán này cũng tương tự như **User-User Collaborative Filtering**.\n","\n","Thay vì tính toán trung bình cộng các đánh giá của users theo cột thì thay vào đó là trung bình cộng các đánh giá cho các items theo hàng của ma trận Utility.\n","\n","Sau đó chuẩn hóa ma trận này bằng cách trừ các đánh giá đã biết của item cho trung bình cộng bình cộng vừa tính được tương ứng của item đó, đồng thời thay các đánh giá chưa biết bằng 0. Thu được ma trận Normalized Utility Matrix.\n","\n","Tiếp theo, tính ma trận tương đồng cho các items. Cuối cùng đưa ra dự đoán như **User-User Collaborative Filtering**."]},{"cell_type":"markdown","metadata":{"id":"8hx03s681JMU","colab_type":"text"},"source":["## **4. Hệ thống Matrix Factorization Collaborative Filtering**\n","\n","Hệ thống **Matrix Factorization Collaborative Filtering** cho rằng tồn tại các tính chất ẩn mô tả sự liên quan giữa các items và users. Mỗi item m sẽ mang tính chất ẩn ở một mức độ nào đó tương ứng với các hệ số trong vector $\\mathbf{x_m}$ của nó, hệ số càng cao tương ứng với việc mang tính chất đó càng cao. Mỗi user n cũng sẽ có xu hướng thích những tính chất ẩn nào đó và được mô tả bởi các hệ số trong vector $\\mathbf{w_n}$ của nó, hệ số cao tương ứng với việc user thích các items có tính chất ẩn đó. Mã nguồn tham khảo chính tại bài viết [Matrix Factorization Collaborative Filtering](https://machinelearningcoban.com/2017/05/31/matrixfactorization/). \n","\n","Hệ thống **Content-based Recommendation** đi tìm là ma trận $\\mathbf{W}$ dựa trên ma trận đặc trưng của items $\\mathbf{X}$ để đưa ra dự đoán yêu thích của user n đối với sản phẩm m. Hệ thống **Matrix Factorization Collaborative Filtering** không xây dựng và dùng toàn bộ thông tin của ma trận $\\mathbf{X}$, mà sẽ đi tìm đồng thời $\\mathbf{X}$ và $\\mathbf{W}$, điều này có thể được hiểu như $\\mathbf{X}$ sẽ được phân thành hai ma trận có kích thước nhỏ hơn là $\\mathbf{W}$ và $\\mathbf{H}$, sao cho ta có thể xây dựng lại $\\mathbf{X}$ từ hai ma trận nhỏ hơn này càng chính xác càng tốt, nghĩa là $\\mathbf{X}\\sim \\mathbf{W}\\mathbf{H^T}$. Với $\\mathbf{X} \\in \\mathbb{R}^{K \\times M}$ là một ma trận mà mỗi cột $\\mathbf{x}_m$ là một véc tơ bao gồm K nhân tố tiềm ẩn mô tả cho item thứ m, $\\mathbf{W} \\in \\mathbb{R}^{K \\times N}$ là một ma trận mà mỗi cột $\\mathbf{x}_m$ là một véc tơ bao gồm $K$ nhân tố tiềm ẩn mô tả cho item thứ m. Bài toán đặt ra là cố gắng xấp xỉ Utility $\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}$ bằng tích hai ma trận $\\mathbf{X} \\in \\mathbb{R}^{K \\times M}$ và $\\mathbf{W} \\in \\mathbb{R}^{K \\times N}$ với $K$ là nhân tố mang tính ẩn.\n","\n","$\\mathbf{Y}\\approx\n","\\left[ \\begin{matrix}\n","{x}_{11} & {x}_{21} & \\dots & {x}_{K1}\\\\\n","{x}_{12} & {x}_{22} & \\dots & {x}_{K2}\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","{x}_{1M} & {x}_{2M} & \\dots & {x}_{KM}\\\\\n","\\end{matrix} \\right]\n","\\left[ \\begin{matrix}\n","{w}_{11} & {w}_{12} & \\dots & {w}_{1N}\\\\\n","{w}_{21} & {w}_{22} & \\dots & {w}_{2N}\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","{w}_{K1} & {w}_{K2} & \\dots & {w}_{KN}\\\\\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}^T_1\\mathbf{w}_1 & \\mathbf{x}^T_1\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_1 \\mathbf{w}_N\\\\\n","\\mathbf{x}^T_2\\mathbf{w}_1 & \\mathbf{x}^T_2\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_2 \\mathbf{w}_N\\\\\n","\\dots & \\dots & \\ddots & \\dots \\\\\n","\\mathbf{x}^T_M\\mathbf{w}_1 & \\mathbf{x}^T_M\\mathbf{w}_2 & \\dots & \\mathbf{x}^T_M \\mathbf{w}_N\\\\\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}^T_1 \\\\\n","\\mathbf{x}^T_2 \\\\\n","\\dots \\\\\n","\\mathbf{x}^T_M \\\\\n","\\end{matrix} \\right]\n","\\left[ \\begin{matrix}\n","\\mathbf{w}_1 & \\mathbf{w}_2 & \\dots & \\mathbf{w}_N\n","\\end{matrix} \\right]=\n","\\left[ \\begin{matrix}\n","\\mathbf{x}_1 & \\mathbf{x}_2 & \\dots & \\mathbf{x}_M\n","\\end{matrix} \\right]^T\\left[ \\begin{matrix}\n","\\mathbf{w}_1 & \\mathbf{w}_2 & \\dots & \\mathbf{w}_N\n","\\end{matrix} \\right]=\n","\\mathbf{X}^{T}\\mathbf{W}$\n","\n","Với $\\mathbf{x}_m$ là của cột ma trận $\\mathbf{X}$ và $\\mathbf{w}_n$ là của cột ma trận $\\mathbf{W}$. Hàm mất mát được xây dựng tương tự **Content-based Recommendation** cho mỗi user n và item m (xét trường hợp đơn giản là không có thành phần bias).\n","\n","$\\mathbb{L}(\\mathbf{x}_m,\\mathbf{w}_n) = \\frac{1}{2s_n} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x_m}^{T}\\mathbf{w_n} - y_{mn})^2 + \\frac{\\lambda}{2}(||\\mathbf{x}_m||_2+||\\mathbf{w}_n||_2)^2 $\n","\n","Bài toán tối ưu hàm $\\mathbb{L}(\\mathbf{x}_m,\\mathbf{w}_n)$ cũng dùng SGD để tìm cặp nghiệm $(\\mathbf{x}_m,\\mathbf{w}_n)$. Cố định $\\mathbf{x}_n$, ta có hàm mất mát theo $\\mathbf{w}_n$.\n","\n","$\\mathbb{L}(\\mathbf{w}_n) = \\frac{1}{2s_n} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m^{T}\\mathbf{w}_n - y_{mn})^2 + \\frac{\\lambda}{2}(||\\mathbf{x}_m||_2+||\\mathbf{w}_n||_2)^2 $\n","\n","Biểu thức trên có thể đơn giản nó bằng cách đặt $\\hat{\\mathbf{X}}_n$ là ma trận được tạo bởi các hàng ứng với các items đã được đánh giá bởi user n, và $\\hat{\\mathbf{y}}_{n}$ là các đánh giá tương ứng. Khi đó:\n","\n","$\\mathbb{L}(\\mathbf{w}_n) = \\frac{1}{2s_n} ||\\hat{\\mathbf{X}}_n^{T}\\mathbf{w}_n - \\hat{\\mathbf{y}}_{n}||^2 + \\frac{\\lambda}{2}(||\\hat{\\mathbf{x}}_n||_2+||\\mathbf{w}_n||_2)^2 $\n","\n","Đạo hàm của hàm mất mát như sau:\n","\n","$\\nabla_{\\mathbf{w}_{n}}\\mathbb{L}(\\mathbf{w}_{n})=\\frac{\\partial \\mathbb{L}(\\mathbf{w}_n)}{\\partial \\mathbf{w}_n} = \\frac{1}{s_n}\\hat{\\mathbf{X}}_n(\\hat{\\mathbf{X}}^T_{n}\\mathbf{w}_n-\\hat{\\mathbf{y}}_n) + \\lambda\\mathbf{w}_n$\n","\n","Áp dụng phương pháp SGD cho mỗi lần cập nhật $\\mathbf{w}_n$\n","\n","$\\mathbf{w}_n = \\mathbf{w}_n - \\eta \\nabla_{\\mathbf{w}_{n}}\\mathbb{L}(\\mathbf{w}_{n}) = \\mathbf{w}_n - \\eta [\\frac{1}{s_n}\\hat{\\mathbf{X}}_n(\\hat{\\mathbf{X}}^T_n\\mathbf{w}_n-\\hat{\\mathbf{y}}_{n}) + \\lambda\\mathbf{w}_n]$\n","\n","Tương tự với phần cố định $\\mathbf{x}_n$, cập nhật của $\\mathbf{w}_n$ là \n","\n","$\\mathbf{x}_m = \\mathbf{x}_m - \\eta \\nabla_{\\mathbf{x}_m}\\mathbb{L}(\\mathbf{x}_{m}) = \\mathbf{x}_m - \\eta [\\frac{1}{s_m}(\\mathbf{x}_{m}\\hat{\\mathbf{W}}_m-\\hat{\\mathbf{y}}_m)\\hat{\\mathbf{W}}_m^T + \\lambda\\mathbf{x}_m]$\n","\n","Với $\\hat{\\mathbf{W}}_m$ là ma trận được tạo bởi các cột ứng với các users đã đánh giá item m, và $\\hat{\\mathbf{y}}_{m}$ là các đánh giá tương ứng.\n"]},{"cell_type":"markdown","metadata":{"id":"uxXogqXNzJbZ","colab_type":"text"},"source":["## **5. Dữ liệu BX-CSV-Dump**"]},{"cell_type":"markdown","metadata":{"id":"PzJtD_WD9qUo","colab_type":"text"},"source":["Dữ liệu được sử dụng cho bài toán bên dưới là dữ liệu [BX-CSV-Dump](http://www2.informatik.uni-freiburg.de/~cziegler/BX/) cho biết các đánh giá mà người dùng đã đánh giá các quyển sách mà họ từng sử dụng, đánh giá được thể hiện trên thang điểm từ 1-10 (giá trị cao hơn biểu thị sự đánh giá cao hơn), phần không đánh giá được hiểu là 0. Cột **User-ID** thể hiện ID của người dùng, cột **ISBN** thể hiện ID của sách, cột **Book-Rating** thể hiện phần đánh giá. Dữ liệu **BX-CSV-Dump** khá lớn nên phần phân tích bên dưới chỉ giới hạn 50000 dòng đầu tiên. Trong 50000 quan sát đó, tách dữ liệu thành 2 phần, phần dữ liệu được đánh giá (giá trị **Book-Rating** khác 0) sẽ làm dữ liệu train và test và phần chưa đánh giá (giá trị **Book-Rating** bằng 0) sẽ được dự đoán các đánh giá user với item  đến mức nào. Hệ thống dùng là **Matrix Factorization Collaborative Filtering**.\n"]},{"cell_type":"code","metadata":{"id":"pzW2-a7_5RVq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"ok","timestamp":1598375517426,"user_tz":-420,"elapsed":1883,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"23c0a9eb-485a-4224-adc1-454fb5ed3485"},"source":["import pandas as pd \n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","path = \"gdrive/My Drive/Recommendation/BX-CSV-Dump/\"\n","rate_base = pd.read_csv(path+'BX-Book-Ratings.csv', sep=';', encoding='latin-1')\n","rate_base = rate_base[:50000]\n","rate_base"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User-ID</th>\n","      <th>ISBN</th>\n","      <th>Book-Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>276725</td>\n","      <td>034545104X</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>276726</td>\n","      <td>0155061224</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>276727</td>\n","      <td>0446520802</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>276729</td>\n","      <td>052165615X</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>276729</td>\n","      <td>0521795028</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>49995</th>\n","      <td>11676</td>\n","      <td>0445405457</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>49996</th>\n","      <td>11676</td>\n","      <td>0445408502</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49997</th>\n","      <td>11676</td>\n","      <td>0445409134</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49998</th>\n","      <td>11676</td>\n","      <td>0445409169</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>49999</th>\n","      <td>11676</td>\n","      <td>0445409207</td>\n","      <td>5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>50000 rows × 3 columns</p>\n","</div>"],"text/plain":["       User-ID        ISBN  Book-Rating\n","0       276725  034545104X            0\n","1       276726  0155061224            5\n","2       276727  0446520802            0\n","3       276729  052165615X            3\n","4       276729  0521795028            6\n","...        ...         ...          ...\n","49995    11676  0445405457            7\n","49996    11676  0445408502            0\n","49997    11676  0445409134            0\n","49998    11676  0445409169            0\n","49999    11676  0445409207            5\n","\n","[50000 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"markdown","metadata":{"id":"x2IfzZOGIByr","colab_type":"text"},"source":["Quan sát cho thấy các ID chưa được mã hóa theo thứ tự nên thực hiện mã hóa các giá trị ID"]},{"cell_type":"code","metadata":{"id":"3cwSdhqhoJB8","colab_type":"code","colab":{}},"source":["from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","rate_base['User-ID'] = le.fit_transform(rate_base['User-ID'])\n","rate_base['ISBN'] = le.fit_transform(rate_base['ISBN'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftZw4Z0SJI1u","colab_type":"text"},"source":["Vì biểu thức hàm mất mát chỉ phụ thuộc vào các items đã được đánh giá, nên ta chỉ trích xuất phần dữ liệu đã được đánh giá để đem phân tích. "]},{"cell_type":"code","metadata":{"id":"k-OlIpmaYouE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598375521454,"user_tz":-420,"elapsed":757,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"b0cad8fc-0e8c-4df3-eb43-79b8be2c74bf"},"source":["rated_base = rate_base[rate_base['Book-Rating']!=0]\n","nonrate_base = rate_base[rate_base['Book-Rating']==0]\n","print('Dữ liệu đã đánh giá: ', rated_base.shape)\n","print('Dữ liệu chưa được đánh giá: ', nonrate_base.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dữ liệu đã đánh giá:  (20962, 3)\n","Dữ liệu chưa được đánh giá:  (29038, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qkkCd4RqPkXx","colab_type":"text"},"source":["Phần dữ liệu đã đánh giá được chia train và test "]},{"cell_type":"code","metadata":{"id":"ohKsdbCKa_H6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598375522829,"user_tz":-420,"elapsed":742,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"ed5726b7-e417-4e53-87d9-40a4d788974f"},"source":["from sklearn.model_selection import train_test_split\n","rated_base_arr = rated_base.values\n","rate_train, rate_test = train_test_split(rated_base_arr, test_size=0.33, random_state=42)\n","rate = rate_train.copy()\n","print ('Dữ liệu train: ', rate_train.shape)\n","print ('Dữ liệu test: ', rate_test.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dữ liệu train:  (14044, 3)\n","Dữ liệu test:  (6918, 3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pfhSPuOijEEN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1598375524566,"user_tz":-420,"elapsed":775,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"2dc8b3d6-f5c1-49b9-9477-b0fb379a6120"},"source":["import numpy as np\n","n_ratings = rate_train.shape[0]\n","n_users = int(np.max(rate_train[:, 0])) + 1\n","n_items = int(np.max(rate_train[:, 1])) + 1 \n","print('Số lượng users: ',n_users)\n","print('Số lượng items: ',n_items)  "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Số lượng users:  5064\n","Số lượng items:  36282\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Cwf09psZKmlv","colab_type":"text"},"source":["Chọn các giá trị mặc định cho ẩn K, phần regularization $\\lambda = 0.1$, bước nhảy gradient của SGD $\\eta = 1$ và số lần cập nhật gradient epoch = 100"]},{"cell_type":"code","metadata":{"id":"-CKY-1YwxJwe","colab_type":"code","colab":{}},"source":["import numpy as np\n","K = 10\n","lamda = .1\n","learning_rate = 1\n","epoch= 100"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VBuuVgZZ2piL","colab_type":"text"},"source":["Chuẩn hóa rating bằng cách trừ các giá trị đánh giá cho trung bình cộng của mỗi user"]},{"cell_type":"code","metadata":{"id":"qncGt4pVsGQD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1598375529178,"user_tz":-420,"elapsed":1537,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"8aec3be3-4601-4453-927b-d8b9ad52be3e"},"source":["mu = np.zeros((n_users,))\n","for n in range(n_users):\n","    ids = np.where(rate_train[:, 0]  == n)[0]\n","    item_ids = rate_train[ids, 1] \n","    ratings = rate_train[ids, 2]\n","    # take mean\n","    m = np.mean(ratings) \n","    if np.isnan(m):\n","        m = 0 \n","    mu[n] = m\n","    rate_train[ids, 2] = ratings - mu[n]    "],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n","  out=out, **kwargs)\n","/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n","  ret = ret.dtype.type(ret / rcount)\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"daJti2WUOIbz","colab_type":"text"},"source":["Khởi tạo ma trận $\\mathbf{X} \\in \\mathbb{R}^{K \\times M}$ và $\\mathbf{W}\\in \\mathbb{R}^{K \\times N}$ với M là số items và N là số users. Kí hiệu X bên dưới thực chất là $\\mathbf{X}^T$"]},{"cell_type":"code","metadata":{"id":"ZLp0BchlM4EG","colab_type":"code","colab":{}},"source":["X = np.random.randn(n_items, K)\n","W = np.random.randn(K, n_users)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oBfVyc8WOo2L","colab_type":"text"},"source":["Xác định các items được đánh giá bởi 1 user, và users đã đánh giá 1 item và các ratings tương ứng:"]},{"cell_type":"code","metadata":{"id":"_kslraFBIZ4G","colab_type":"code","colab":{}},"source":["def get_items_rated_by_user(user_id):\n","    ids = np.where(rate_train[:,0] == user_id)[0]\n","    item_ids = rate_train[ids, 1]\n","    ratings = rate_train[ids, 2]\n","    return (item_ids, ratings)\n","        \n","        \n","def get_users_who_rate_item(item_id):\n","    ids = np.where(rate_train[:,1] == item_id)[0] \n","    user_ids = rate_train[ids, 0]\n","    ratings = rate_train[ids, 2]\n","    return (user_ids, ratings)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lKJGixTaPIiz","colab_type":"text"},"source":["Tiến hành cập nhật ma trận $\\mathbf{X}^T$ và $\\mathbf{W}$"]},{"cell_type":"code","metadata":{"id":"R7QDE2e2hLYi","colab_type":"code","colab":{}},"source":["def updateX(X):\n","    for m in range(n_items):\n","        user_ids, ratings = get_users_who_rate_item(m)\n","        Wm = W[:, user_ids]\n","        # gradient\n","        grad_xm = (X[m, :].dot(Wm) - ratings).dot(Wm.T)/n_ratings + lamda*X[m, :]\n","        X[m, :] -= learning_rate*grad_xm.reshape((K,))\n","    \n","def updateW(W):\n","    for n in range(n_users):\n","        item_ids, ratings = get_items_rated_by_user(n)\n","        Xn = X[item_ids, :]\n","        # gradient\n","        grad_wn = Xn.T.dot(Xn.dot(W[:, n]) - ratings)/n_ratings + lamda*W[:, n]\n","        W[:, n] -= learning_rate*grad_wn.reshape((K,))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AjZfIVA1PWLI","colab_type":"text"},"source":["Dự đoán các giá trị đánh giá bởi user và itemn $y_{mn}=\\mathbf{x}_m^{T}\\mathbf{w}_n+b_{n}$, $m=\\overline{1..M}, n=\\overline{1..N}$"]},{"cell_type":"code","metadata":{"id":"m74IW5KFqsJE","colab_type":"code","colab":{}},"source":["def pred(user, item):\n","    user = int(user)\n","    item = int(item)\n","    bias = mu[user]\n","    pred = X[item, :].dot(W[:, user]) + bias\n","    return pred  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QiMNnLblPkEp","colab_type":"text"},"source":["Định nghĩa hàm mất mát"]},{"cell_type":"code","metadata":{"id":"Gq3O1PbxSosT","colab_type":"code","colab":{}},"source":["def loss(rating, X, W):\n","        L = 0 \n","        for i in range(rating.shape[0]):\n","            # user, item, rating\n","            n, m, rate = int(rating[i, 0]), int(rating[i, 1]), rating[i, 2]\n","            L += 0.5*(rate - X[m, :].dot(W[:, n]))**2\n","        \n","        L /= rating.shape[0]\n","        L += 0.5*lamda*(np.linalg.norm(X, 'fro') + np.linalg.norm(W, 'fro'))\n","        return L "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7UgQAGXPhBI","colab_type":"text"},"source":["Đánh giá mô hình bằng RMSE"]},{"cell_type":"code","metadata":{"id":"T1XoPX-jqaVC","colab_type":"code","colab":{}},"source":["def evaluate_RMSE(rate):\n","    n = rate.shape[0]\n","    SE = 0 # squared error\n","    for i in range(n):\n","        predict = pred(rate[i, 0], rate[i, 1])        \n","        SE += (predict - rate[i, 2])**2 \n","        RMSE = np.sqrt(SE/n)\n","    return RMSE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t_NhpNG5PpeW","colab_type":"text"},"source":["Fit dữ liệu, tìm $\\mathbf{X}$ và $\\mathbf{W}$ tối ưu hàm mất mát"]},{"cell_type":"code","metadata":{"id":"u6FlDRrhp7Kp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598375711604,"user_tz":-420,"elapsed":170375,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"c7dc9a3f-bab7-48e4-f2ab-e8872aa24eb1"},"source":["for it in range(epoch):\n","    updateX(X)\n","    updateW(W)\n","    rmse_train = evaluate_RMSE(rate)\n","    print ('epoch =', it + 1, ', loss =', loss(rate_train, X, W), ', RMSE train =', rmse_train)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["epoch = 1 , loss = 41.005052206978846 , RMSE train = 2.8905447155804103\n","epoch = 2 , loss = 36.13353166783798 , RMSE train = 2.46010048069914\n","epoch = 3 , loss = 32.06896155075741 , RMSE train = 2.1490307442029626\n","epoch = 4 , loss = 28.602701020965668 , RMSE train = 1.9264605502708625\n","epoch = 5 , loss = 25.60147069469833 , RMSE train = 1.7695696275973518\n","epoch = 6 , loss = 22.974787572116384 , RMSE train = 1.6607549466152944\n","epoch = 7 , loss = 20.658126267749513 , RMSE train = 1.5864102898400092\n","epoch = 8 , loss = 18.603513564524928 , RMSE train = 1.5362501172134835\n","epoch = 9 , loss = 16.773971407678044 , RMSE train = 1.502736315000597\n","epoch = 10 , loss = 15.140093949090966 , RMSE train = 1.480507387580178\n","epoch = 11 , loss = 13.677869231253617 , RMSE train = 1.4658429018551036\n","epoch = 12 , loss = 12.367254187220677 , RMSE train = 1.4562085970497398\n","epoch = 13 , loss = 11.191218483692847 , RMSE train = 1.4499007300565072\n","epoch = 14 , loss = 10.135086680315682 , RMSE train = 1.4457841163353045\n","epoch = 15 , loss = 9.186073811636058 , RMSE train = 1.4431068900538049\n","epoch = 16 , loss = 8.332948590638395 , RMSE train = 1.4413730181527495\n","epoch = 17 , loss = 7.565782306476558 , RMSE train = 1.440256101943002\n","epoch = 18 , loss = 6.875756345502879 , RMSE train = 1.439541755373177\n","epoch = 19 , loss = 6.25501064439556 , RMSE train = 1.4390893634993236\n","epoch = 20 , loss = 5.696521374548754 , RMSE train = 1.438806816930561\n","epoch = 21 , loss = 5.194000019597732 , RMSE train = 1.4386338650747328\n","epoch = 22 , loss = 4.741808520176177 , RMSE train = 1.4385311659645184\n","epoch = 23 , loss = 4.334886807466255 , RMSE train = 1.4384730900887477\n","epoch = 24 , loss = 3.968690136790833 , RMSE train = 1.4384429938421073\n","epoch = 25 , loss = 3.639134360134846 , RMSE train = 1.438430116124853\n","epoch = 26 , loss = 3.342547767727736 , RMSE train = 1.4384275412664385\n","epoch = 27 , loss = 3.0756284648075622 , RMSE train = 1.438430862343001\n","epoch = 28 , loss = 2.835406483062279 , RMSE train = 1.438437304518169\n","epoch = 29 , loss = 2.619209991312183 , RMSE train = 1.438445150532943\n","epoch = 30 , loss = 2.424635089207089 , RMSE train = 1.4384533646457711\n","epoch = 31 , loss = 2.2495187558178444 , RMSE train = 1.4384613468972145\n","epoch = 32 , loss = 2.0919145917438775 , RMSE train = 1.438468772933941\n","epoch = 33 , loss = 1.9500710452053633 , RMSE train = 1.438475489971555\n","epoch = 34 , loss = 1.8224118538604004 , RMSE train = 1.4384814495573621\n","epoch = 35 , loss = 1.707518467697008 , RMSE train = 1.4384866644215462\n","epoch = 36 , loss = 1.6041142462759774 , RMSE train = 1.4384911810618848\n","epoch = 37 , loss = 1.5110502472101475 , RMSE train = 1.4384950625730306\n","epoch = 38 , loss = 1.4272924430106657 , RMSE train = 1.4384983781168674\n","epoch = 39 , loss = 1.3519102209928286 , RMSE train = 1.4385011966707906\n","epoch = 40 , loss = 1.2840660363049832 , RMSE train = 1.438503583507104\n","epoch = 41 , loss = 1.2230061016925142 , RMSE train = 1.4385055983937123\n","epoch = 42 , loss = 1.1680520096138136 , RMSE train = 1.4385072948594722\n","epoch = 43 , loss = 1.1185931930053354 , RMSE train = 1.4385087200995337\n","epoch = 44 , loss = 1.0740801405229654 , RMSE train = 1.4385099152481156\n","epoch = 45 , loss = 1.0340182906099604 , RMSE train = 1.4385109158459912\n","epoch = 46 , loss = 0.9979625363764292 , RMSE train = 1.4385117523948052\n","epoch = 47 , loss = 0.9655122801229528 , RMSE train = 1.4385124509325422\n","epoch = 48 , loss = 0.9363069824883583 , RMSE train = 1.4385130335918717\n","epoch = 49 , loss = 0.9100221567234262 , RMSE train = 1.4385135191202532\n","epoch = 50 , loss = 0.8863657635556195 , RMSE train = 1.4385139233517938\n","epoch = 51 , loss = 0.8650749665718221 , RMSE train = 1.4385142596274163\n","epoch = 52 , loss = 0.8459132120591943 , RMSE train = 1.4385145391642307\n","epoch = 53 , loss = 0.8286676008537088 , RMSE train = 1.4385147713767197\n","epoch = 54 , loss = 0.8131465229934105 , RMSE train = 1.43851496415418\n","epoch = 55 , loss = 0.7991775288950679 , RMSE train = 1.4385151240987297\n","epoch = 56 , loss = 0.7866054134019909 , RMSE train = 1.438515256728571\n","epoch = 57 , loss = 0.7752904914164649 , RMSE train = 1.4385153666509172\n","epoch = 58 , loss = 0.7651070459591415 , RMSE train = 1.4385154577085215\n","epoch = 59 , loss = 0.7559419314136908 , RMSE train = 1.4385155331036878\n","epoch = 60 , loss = 0.7476933164391298 , RMSE train = 1.4385155955027344\n","epoch = 61 , loss = 0.7402695525840467 , RMSE train = 1.4385156471240572\n","epoch = 62 , loss = 0.733588156033369 , RMSE train = 1.4385156898120037\n","epoch = 63 , loss = 0.7275748911752422 , RMSE train = 1.4385157250989922\n","epoch = 64 , loss = 0.7221629458067136 , RMSE train = 1.4385157542574134\n","epoch = 65 , loss = 0.7172921888150158 , RMSE train = 1.4385157783431803\n","epoch = 66 , loss = 0.7129085020874059 , RMSE train = 1.4385157982320476\n","epoch = 67 , loss = 0.7089631792271721 , RMSE train = 1.4385158146499901\n","epoch = 68 , loss = 0.7054123843956865 , RMSE train = 1.4385158281985064\n","epoch = 69 , loss = 0.7022166652681625 , RMSE train = 1.4385158393757491\n","epoch = 70 , loss = 0.6993405146921536 , RMSE train = 1.4385158485940708\n","epoch = 71 , loss = 0.6967519761786553 , RMSE train = 1.4385158561946727\n","epoch = 72 , loss = 0.6944222888429127 , RMSE train = 1.438515862459765\n","epoch = 73 , loss = 0.6923255678501083 , RMSE train = 1.4385158676226775\n","epoch = 74 , loss = 0.6904385168154844 , RMSE train = 1.4385158718762363\n","epoch = 75 , loss = 0.6887401689637974 , RMSE train = 1.4385158753797649\n","epoch = 76 , loss = 0.6872116541721508 , RMSE train = 1.438515878264838\n","epoch = 77 , loss = 0.6858359893079745 , RMSE train = 1.4385158806400944\n","epoch = 78 , loss = 0.6845978895327879 , RMSE train = 1.438515882595186\n","epoch = 79 , loss = 0.6834835984751853 , RMSE train = 1.438515884204108\n","epoch = 80 , loss = 0.6824807353861387 , RMSE train = 1.4385158855278743\n","epoch = 81 , loss = 0.6815781575785901 , RMSE train = 1.4385158866168037\n","epoch = 82 , loss = 0.6807658366227355 , RMSE train = 1.4385158875123873\n","epoch = 83 , loss = 0.6800347469216685 , RMSE train = 1.4385158882488207\n","epoch = 84 , loss = 0.679376765429216 , RMSE train = 1.438515888854266\n","epoch = 85 , loss = 0.6787845813958765 , RMSE train = 1.4385158893519436\n","epoch = 86 , loss = 0.6782516151400334 , RMSE train = 1.4385158897609627\n","epoch = 87 , loss = 0.6777719449419412 , RMSE train = 1.438515890097055\n","epoch = 88 , loss = 0.6773402412481896 , RMSE train = 1.4385158903731834\n","epoch = 89 , loss = 0.6769517074556849 , RMSE train = 1.4385158906000215\n","epoch = 90 , loss = 0.6766020266171269 , RMSE train = 1.438515890786321\n","epoch = 91 , loss = 0.6762873134759031 , RMSE train = 1.4385158909393119\n","epoch = 92 , loss = 0.6760040712974159 , RMSE train = 1.4385158910649336\n","epoch = 93 , loss = 0.6757491530172435 , RMSE train = 1.4385158911680687\n","epoch = 94 , loss = 0.67551972627447 , RMSE train = 1.4385158912527187\n","epoch = 95 , loss = 0.6753132419415879 , RMSE train = 1.4385158913222074\n","epoch = 96 , loss = 0.6751274058014319 , RMSE train = 1.4385158913792246\n","epoch = 97 , loss = 0.674960153056387 , RMSE train = 1.438515891426015\n","epoch = 98 , loss = 0.6748096253866203 , RMSE train = 1.438515891464397\n","epoch = 99 , loss = 0.6746741503024839 , RMSE train = 1.4385158914958884\n","epoch = 100 , loss = 0.6745522225617057 , RMSE train = 1.438515891521721\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LE8T2EhzP5KB","colab_type":"text"},"source":["Ta nhận thấy rằng giá trị loss giảm dần về 0 và RMSE train cũng giảm dần khi số vòng lặp tăng lên. Với $\\mathbf{X}^T$ và $\\mathbf{W}$ đã được cập nhật kết quả cuối cùng"]},{"cell_type":"code","metadata":{"id":"VnKHXfmpuwyV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1598377633622,"user_tz":-420,"elapsed":1229,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"c99c28bb-ec79-42c6-ebfc-429ef2c97545"},"source":["X,W"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[ 7.91090888e-06, -4.99338609e-05, -1.07704160e-06, ...,\n","          1.51214859e-05,  3.73341333e-05, -2.59563172e-05],\n","        [ 1.07793178e-05, -1.02062450e-05,  1.82141524e-05, ...,\n","         -1.59148901e-05, -8.09717231e-06,  1.98768177e-05],\n","        [-9.98031586e-06,  1.43135397e-05,  3.10102047e-05, ...,\n","         -2.98386735e-05,  1.06454519e-05, -1.67857229e-05],\n","        ...,\n","        [-2.25050387e-05,  2.92543004e-06, -4.34073873e-05, ...,\n","          2.76816628e-05,  1.43320408e-05,  2.75149720e-05],\n","        [-1.06757136e-05, -2.93149933e-06, -5.43480235e-05, ...,\n","          3.38478080e-05,  6.55606563e-05,  1.09708328e-05],\n","        [-7.04678221e-05,  3.70912913e-05, -3.31392236e-05, ...,\n","         -2.52122363e-06, -1.54209857e-05, -2.33123712e-05]]),\n"," array([[-2.38325883e-05,  5.14508536e-05,  1.04793587e-05, ...,\n","          1.94116972e-05, -1.46107224e-05, -3.93945584e-05],\n","        [-5.68539346e-05,  1.67593373e-05,  3.26653122e-05, ...,\n","         -2.33056298e-05, -2.17611592e-05,  8.99902370e-06],\n","        [-2.43675102e-05,  2.68189477e-05, -2.67130582e-08, ...,\n","         -2.43067745e-05,  4.19662376e-05, -2.06579111e-05],\n","        ...,\n","        [-8.39456922e-06,  1.13278976e-05, -4.04859847e-06, ...,\n","          7.63637047e-06,  2.57604249e-05,  4.53254085e-05],\n","        [ 1.12239895e-06,  5.21990329e-06, -2.46471634e-05, ...,\n","         -1.77447424e-05,  6.88497611e-06,  5.18403951e-05],\n","        [-1.70717325e-05,  3.10824673e-05, -1.31352260e-05, ...,\n","          8.21429653e-06, -3.07165625e-06, -3.47863428e-06]]))"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"SO73Rnbouspc","colab_type":"text"},"source":["Tiếp theo, đánh giá mô hình bằng dữ liệu test: đưa ra giá trị dự đoán cho dữ liệu test, qua đó cho biết RMSE của test"]},{"cell_type":"code","metadata":{"id":"UlXpKymUeoOW","colab_type":"code","colab":{}},"source":["def pred_for_user(data):\n","    predicted_ratings = np.zeros((data.shape[0],))\n","    item_ids = np.zeros((data.shape[0],))\n","    for i in range(data.shape[0]):\n","        user_id = data[i,0]\n","        ids = np.where(data[:, 0] == user_id)[0]\n","        for i in ids:\n","            predicted_ratings[ids] = round(X[data[i, 1],:].dot(W[:, user_id]) + mu[user_id],2)\n","    return predicted_ratings"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q4thoybEOk3q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":436},"executionInfo":{"status":"ok","timestamp":1598376584614,"user_tz":-420,"elapsed":10467,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"c10dff2f-a89a-4026-9113-69aee0b0259e"},"source":["RMSE = evaluate_RMSE(rate_test)\n","test_table = pd.DataFrame()\n","test_table['User-ID']=le.inverse_transform(rate_test[:,0])\n","test_table['ISBN']=le.inverse_transform(rate_test[:,1])\n","test_table['Book-Rating']=rate_test[:,2]\n","test_table['Predict-Rating'] = pred_for_user(rate_test)\n","print('RMSE test:', RMSE)\n","test_table"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RMSE test: 3.1991364901247517\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User-ID</th>\n","      <th>ISBN</th>\n","      <th>Book-Rating</th>\n","      <th>Predict-Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>009964990X</td>\n","      <td>0812967240</td>\n","      <td>7</td>\n","      <td>7.24</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0140089233</td>\n","      <td>0689829507</td>\n","      <td>10</td>\n","      <td>8.45</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>014005829X</td>\n","      <td>0099422794</td>\n","      <td>6</td>\n","      <td>6.86</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>000638384X</td>\n","      <td>0679879242</td>\n","      <td>8</td>\n","      <td>7.92</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0064440214</td>\n","      <td>0553584782</td>\n","      <td>10</td>\n","      <td>8.28</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6913</th>\n","      <td>0140149902</td>\n","      <td>0345380371</td>\n","      <td>9</td>\n","      <td>7.33</td>\n","    </tr>\n","    <tr>\n","      <th>6914</th>\n","      <td>0060923245</td>\n","      <td>0771086598</td>\n","      <td>8</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>6915</th>\n","      <td>0006165338</td>\n","      <td>9728440383</td>\n","      <td>8</td>\n","      <td>7.93</td>\n","    </tr>\n","    <tr>\n","      <th>6916</th>\n","      <td>0006542808</td>\n","      <td>038549825X</td>\n","      <td>8</td>\n","      <td>7.71</td>\n","    </tr>\n","    <tr>\n","      <th>6917</th>\n","      <td>014043478X</td>\n","      <td>0330419560</td>\n","      <td>10</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6918 rows × 4 columns</p>\n","</div>"],"text/plain":["         User-ID        ISBN  Book-Rating  Predict-Rating\n","0     009964990X  0812967240            7            7.24\n","1     0140089233  0689829507           10            8.45\n","2     014005829X  0099422794            6            6.86\n","3     000638384X  0679879242            8            7.92\n","4     0064440214  0553584782           10            8.28\n","...          ...         ...          ...             ...\n","6913  0140149902  0345380371            9            7.33\n","6914  0060923245  0771086598            8            0.00\n","6915  0006165338  9728440383            8            7.93\n","6916  0006542808  038549825X            8            7.71\n","6917  014043478X  0330419560           10            0.00\n","\n","[6918 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"vefKPsgFDvto","colab_type":"text"},"source":["Dự đoán phần không được người dùng đánh giá"]},{"cell_type":"code","metadata":{"id":"reJLG2tO4Yoi","colab_type":"code","colab":{}},"source":["nonrate_base_arr = nonrate_base.values\n","predict_nonrate = pred_for_user(nonrate_base_arr)\n","RMSE_nonrate = evaluate_RMSE(nonrate_base_arr)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vMvUE20Lrh72","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":453},"executionInfo":{"status":"ok","timestamp":1598377352635,"user_tz":-420,"elapsed":1401,"user":{"displayName":"Ngân Kim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg3jE5-sxNkR7JbnJT7u7RuzopwUyOzrBg2L6PauQ=s64","userId":"07539399041725415843"}},"outputId":"b45fcb17-a15c-4b1e-f594-7aa3f64273bb"},"source":["nonrate_table = pd.DataFrame()\n","nonrate_table['User-ID']=le.inverse_transform(nonrate_base_arr[:,0])\n","nonrate_table['ISBN']=le.inverse_transform(nonrate_base_arr[:,1])\n","nonrate_table['Predict-Rating'] = predict_nonrate\n","print('Phần không được người dùng đánh giá', len(nonrate_table))\n","print('Phần được dự đoán: ', len(nonrate_table[nonrate_table['Predict-Rating']!=0]))\n","nonrate_table[nonrate_table['Predict-Rating']!=0]"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Phần không được người dùng đánh giá 29038\n","Phần được dự đoán:  26424\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>User-ID</th>\n","      <th>ISBN</th>\n","      <th>Predict-Rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>9</th>\n","      <td>0241140773</td>\n","      <td>0451192001</td>\n","      <td>7.75</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>0241140773</td>\n","      <td>0609801279</td>\n","      <td>7.75</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>0241140773</td>\n","      <td>1570231028</td>\n","      <td>7.75</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>0241141095</td>\n","      <td>3442437407</td>\n","      <td>6.00</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>0241141788</td>\n","      <td>033390804X</td>\n","      <td>8.00</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>29033</th>\n","      <td>0233981071</td>\n","      <td>0445203609</td>\n","      <td>7.41</td>\n","    </tr>\n","    <tr>\n","      <th>29034</th>\n","      <td>0233981071</td>\n","      <td>0445203668</td>\n","      <td>7.41</td>\n","    </tr>\n","    <tr>\n","      <th>29035</th>\n","      <td>0233981071</td>\n","      <td>0445408502</td>\n","      <td>7.41</td>\n","    </tr>\n","    <tr>\n","      <th>29036</th>\n","      <td>0233981071</td>\n","      <td>0445409134</td>\n","      <td>7.41</td>\n","    </tr>\n","    <tr>\n","      <th>29037</th>\n","      <td>0233981071</td>\n","      <td>0445409169</td>\n","      <td>7.41</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>26424 rows × 3 columns</p>\n","</div>"],"text/plain":["          User-ID        ISBN  Predict-Rating\n","9      0241140773  0451192001            7.75\n","10     0241140773  0609801279            7.75\n","11     0241140773  1570231028            7.75\n","12     0241141095  3442437407            6.00\n","13     0241141788  033390804X            8.00\n","...           ...         ...             ...\n","29033  0233981071  0445203609            7.41\n","29034  0233981071  0445203668            7.41\n","29035  0233981071  0445408502            7.41\n","29036  0233981071  0445409134            7.41\n","29037  0233981071  0445409169            7.41\n","\n","[26424 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"markdown","metadata":{"id":"dpFlE3YHznh9","colab_type":"text"},"source":["TÀI LIỆU THAM KHẢO\n","\n","https://www.sciencedirect.com/science/article/pii/S1877050915007462\n","\n","https://medium.com/sfu-cspmp/recommendation-systems-collaborative-filtering-using-matrix-factorization-simplified-2118f4ef2cd3\n","\n","https://machinelearningcoban.com/2017/05/31/matrixfactorization/\n","\n","https://machinelearningcoban.com/2017/05/24/collaborativefiltering/\n","\n","https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/"]}]}